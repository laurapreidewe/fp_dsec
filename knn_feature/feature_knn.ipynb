{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86be3b1-6f37-47a2-871c-d19d87e3aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyimagesearch.localbinarypatterns import LocalBinaryPatterns\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from imutils import paths\n",
    "# import argparse\n",
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import the necessary packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59733863-38b3-4343-a3f9-ff9bc2bbda15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaborfilter():\n",
    "    # This function is designed to produce a set of GaborFilters \n",
    "    # an even distribution of theta values equally distributed amongst pi rad / 180 degree\n",
    "     \n",
    "    filters = []\n",
    "    num_filters = 16\n",
    "    ksize = 35  # The local area to evaluate\n",
    "    sigma = 3.0  # Larger Values produce more edges\n",
    "    lambd = 10.0\n",
    "    gamma = 0.5\n",
    "    psi = 0  # Offset value - lower generates cleaner results\n",
    "    for theta in np.arange(0, np.pi, np.pi / num_filters):  # Theta is the orientation for edge detection\n",
    "        kern = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_64F)\n",
    "        kern /= 1.0 * kern.sum()  # Brightness normalization\n",
    "        filters.append(kern)\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb3c1116-bfff-4cb9-949c-e4c76c3b0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membuat kernel Gabor\n",
    "def gabor_kernel(size, theta, lambd, sigma, gamma):\n",
    "    kernel = cv2.getGaborKernel((size, size), sigma, theta, lambd, gamma, 0, ktype=cv2.CV_32F)\n",
    "    return kernel\n",
    "\n",
    "# Fungsi untuk menerapkan Gabor filter ke citra\n",
    "def apply_gabor_filter(image, kernels):\n",
    "    filtered_images = [cv2.filter2D(image, cv2.CV_8UC3, k) for k in kernels]\n",
    "    return filtered_images\n",
    "\n",
    "# Fungsi untuk mengambil fitur dari gambar hasil Gabor filter\n",
    "def extract_features_from_gabor_images(gabor_images):\n",
    "    features = [image.flatten() for image in gabor_images]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a347a6c0-868c-47c6-bf9a-7403d117ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(img, filters):\n",
    "# This general function is designed to apply filters to our image\n",
    "     \n",
    "    # First create a numpy array the same size as our input image\n",
    "    newimage = np.zeros_like(img)\n",
    "     \n",
    "    # Starting with a blank image, we loop through the images and apply our Gabor Filter\n",
    "    # On each iteration, we take the highest value (super impose), until we have the max value across all filters\n",
    "    # The final image is returned\n",
    "    depth = -1 # remain depth same as original image\n",
    "     \n",
    "    for kern in filters:  # Loop through the kernels in our GaborFilter\n",
    "        image_filter = cv2.filter2D(img, depth, kern)  #Apply filter to image\n",
    "         \n",
    "        # Using Numpy.maximum to compare our filter and cumulative image, taking the higher value (max)\n",
    "        np.maximum(newimage, image_filter, newimage)\n",
    "    return newimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60dca5ca-6004-4d97-96b6-a350eafcc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(30, 30)):\n",
    "\t# resize the image to a fixed size, then flatten the image into\n",
    "\t# a list of raw pixel intensities\n",
    "\treturn cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e28e3bf-58e5-486c-8c11-382e9c90cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "\t# extract a 3D color histogram from the HSV color space using\n",
    "\t# the supplied number of `bins` per channel\n",
    "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "\t\t[0, 180, 0, 256, 0, 256])\n",
    "\tcv2.normalize(hist, hist)\n",
    "\treturn hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bed5f272-3eb0-4ec5-86bd-c94f9bda36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plt stuff\n",
    "def showimage(myimage, figsize=[10,10]):\n",
    "    if (myimage.ndim>2):  #This only applies to RGB or RGBA images (e.g. not to Black and White images)\n",
    "        myimage = myimage[:,:,::-1] #OpenCV follows BGR order, while matplotlib likely follows RGB order\n",
    "         \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(myimage, cmap = 'gray', interpolation = 'bicubic')\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeb9724a-5e49-4a7b-9ad0-8b5d7433ae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] describing images...\n"
     ]
    }
   ],
   "source": [
    "# the data and label lists\n",
    "#desc = LocalBinaryPatterns(24, 8)\n",
    "data = []\n",
    "print(\"[INFO] describing images...\")\n",
    "train_dir = \"/home/hifzhil/myWork/DSEC/Dataset/dataset\"\n",
    "\n",
    "\n",
    "#labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bffc72f2-881d-4b33-aecd-ce80edfaee37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 2/57\n",
      "[INFO] processed 4/53\n",
      "[INFO] processed 6/53\n",
      "[INFO] processed 8/51\n",
      "[INFO] processed 10/54\n",
      "[INFO] processed 12/54\n",
      "[INFO] processed 14/57\n",
      "[INFO] processed 16/59\n",
      "[INFO] processed 18/59\n",
      "[INFO] processed 20/61\n",
      "[INFO] processed 22/57\n",
      "[INFO] processed 24/57\n",
      "[INFO] processed 26/59\n",
      "[INFO] processed 28/61\n",
      "[INFO] processed 30/61\n",
      "[INFO] processed 32/59\n"
     ]
    }
   ],
   "source": [
    "#for raw image (natural image)\n",
    "rawImages = []\n",
    "\n",
    "#for histogram feature KNN\n",
    "features = []\n",
    "\n",
    "#for texture extraction data\n",
    "textures = []\n",
    "\n",
    "#for label\n",
    "labels = []\n",
    "\n",
    "#texture extraction using gabor\n",
    "gfilters = create_gaborfilter()\n",
    "size = 11\n",
    "theta = 0\n",
    "lambd = 5.0\n",
    "sigma = 1.0\n",
    "gamma = 0.02\n",
    "i = 0\n",
    "\n",
    "gabor_kernels = [gabor_kernel(size, theta, lambd, sigma, gamma * i) for i in range(1)]\n",
    "\n",
    "for (imagePath) in paths.list_images(train_dir):\n",
    "    # load the image, convert it to grayscale, and describe it\n",
    "    image = cv2.imread(imagePath)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #hist = desc.describe(gray)\n",
    "    \n",
    "    #for raw data\n",
    "    pixels = image_to_feature_vector(image)\n",
    "    \n",
    "    #for histogram data\n",
    "    hist = extract_color_histogram(image)\n",
    "\n",
    "    #for texture data\n",
    "    image_g = apply_filter(image, gfilters)\n",
    "    image_gb = image_to_feature_vector(image_g)\n",
    "    # gabor_kernels = [gabor_kernel(size, theta, lambd, sigma, gamma * i) for i in range(4)]\n",
    "\n",
    "    # # Terapkan Gabor filter ke citra\n",
    "    # filtered_images = apply_gabor_filter(image, gabor_kernels)\n",
    "\n",
    "    # # Ekstrak fitur dari gambar hasil Gabor filter\n",
    "    # feature_vector = extract_features_from_gabor_images(filtered_images)\n",
    "\n",
    "    \n",
    "# extract the label from the image path, then update the\n",
    "    # label and data lists\n",
    "    labels.append(imagePath.split(os.path.sep)[-2])\n",
    "    #data.append(hist)\n",
    "    rawImages.append(pixels)\n",
    "    features.append(hist)\n",
    "    textures.append(image_gb)\n",
    "    i+=1\n",
    "    if i > 0 and i % 2 == 0:\n",
    "        print(\"[INFO] processed {}/{}\".format(i, len(imagePath)))\n",
    "# # train a Linear SVM on the data\n",
    "# model = LinearSVC(C=100.0, random_state=42)\n",
    "# model.fit(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad1f70e-76f7-4a94-8623-0de1b86ff477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['penghapus', 'penghapus', 'penghapus', 'panci', 'panci', 'panci', 'oli', 'oli', 'oli', 'liquid', 'liquid', 'liquid', 'teh_celup', 'teh_celup', 'teh_celup', 'tolak_angin', 'tolak_angin', 'tolak_angin', 'gelas_plastik', 'gelas_plastik', 'gelas_plastik', 'jam_weker', 'jam_weker', 'jam_weker', 'botol_putih', 'botol_putih', 'botol_putih', 'jangka_sorong', 'jangka_sorong', 'jangka_sorong', 'teko_heater', 'teko_heater', 'teko_heater']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f11540-b9ca-422f-9c06-f234bf51ef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pixels matrix: 0.09MB\n",
      "[INFO] features matrix: 0.07MB\n",
      "[INFO] textures matrix: 0.09MB\n"
     ]
    }
   ],
   "source": [
    "rawImages = np.array(rawImages)\n",
    "features = np.array(features)\n",
    "textures = np.array(textures)\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(\n",
    "\trawImages.nbytes / (1024 * 1000.0)))\n",
    "print(\"[INFO] features matrix: {:.2f}MB\".format(\n",
    "\tfeatures.nbytes / (1024 * 1000.0)))\n",
    "print(\"[INFO] textures matrix: {:.2f}MB\".format(\n",
    "\ttextures.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25dc2da1-3c7d-4a05-b735-b85cc02fefbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits, using 75%\n",
    "# of the data for training and the remaining 25% for testing\n",
    "(trainRI, testRI, trainRL, testRL) = train_test_split(\n",
    "\trawImages, labels, test_size=0.25, random_state=42)\n",
    "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n",
    "\tfeatures, labels, test_size=0.25, random_state=42)\n",
    "(trainTI, testTI, trainTL, testTL) = train_test_split(\n",
    "\ttextures, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80f7b2fa-2970-4eb6-a987-6f97694af9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating raw pixel accuracy...\n",
      "[INFO] raw pixel accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate a k-NN classifer on the raw pixel intensities\n",
    "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
    "model_raw = KNeighborsClassifier(n_neighbors=3,\n",
    "\tn_jobs=-1)\n",
    "model_raw.fit(trainRI, trainRL)\n",
    "acc = model_raw.score(testRI, testRL)\n",
    "print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "280044c7-9cac-42d3-a704-74819a183af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating histogram accuracy...\n",
      "[INFO] histogram accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate a k-NN classifer on the histogram representations\n",
    "print(\"[INFO] evaluating histogram accuracy...\")\n",
    "model_hist = KNeighborsClassifier(n_neighbors=3,\n",
    "\tn_jobs=-1)\n",
    "model_hist.fit(trainFeat, trainLabels)\n",
    "predic_now = model_hist.predict(trainFeat)\n",
    "acc = model_hist.score(testFeat, testLabels)\n",
    "print(\"[INFO] histogram accuracy: {:.2f}%\".format(acc * 100))\n",
    "#print(\"[INFO] Prediction : {:.2f}%\".format(predic_now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e5f14dc-6933-4d17-8f7a-8c27213a4301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating textures accuracy...\n",
      "[INFO] textures accuracy: 55.56%\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate a k-NN classifer on the raw pixel intensities\n",
    "print(\"[INFO] evaluating textures accuracy...\")\n",
    "model_texture = KNeighborsClassifier(n_neighbors=3,\n",
    "\tn_jobs=-1)\n",
    "model_texture.fit(trainTI, trainTL)\n",
    "acc = model_texture.score(testTI, testTL)\n",
    "print(\"[INFO] textures accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97dd83bc-6e84-41e5-b881-90b47c4f61c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "what model you need ? \n",
      " (1) Pure / Raw  \n",
      " (2) Hist \n",
      " (3) Texture \n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "what_model_you_need = input('what model you need ? \\n (1) Pure / Raw  \\n (2) Hist \\n (3) Texture \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e8f4e0d-45b4-4f41-b610-270290cf7fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "what object should search for? oli\n"
     ]
    }
   ],
   "source": [
    "what_you_looking = input('what object should search for?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb7a29-4300-45dc-890e-98a46ff5c749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penghapus\n",
      "penghapus\n",
      "penghapus\n",
      "panci\n",
      "panci\n",
      "gelas_plastik\n",
      "liquid\n",
      "oli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "for imagePath in paths.list_images(train_dir):\n",
    "  # load the image, convert it to grayscale, describe it,\n",
    "  # and classify it \n",
    "  image = cv2.imread(imagePath)\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  #hist = desc.describe(gray)\n",
    "  hist_image = extract_color_histogram(image)\n",
    "  test_image = image_to_feature_vector(image)\n",
    "  if(what_model_you_need == \"1\") :\n",
    "      model = model_raw\n",
    "  elif(what_model_you_need == \"2\") :\n",
    "      model = model_hist\n",
    "  elif(what_model_you_need == \"3\") :\n",
    "      model = model_texture\n",
    "  ### don't forget to make it as numpy before testing\n",
    "  prediction = model.predict(np.array([test_image]))\n",
    "  # display the image and the prediction\n",
    "  scale_percent = 50\n",
    "  scaled_factor = (int(image.shape[1] * scale_percent / 100), int(image.shape[0] * scale_percent / 100))\n",
    "  image_show = cv2.resize(image, scaled_factor, interpolation=cv2.INTER_AREA)\n",
    "  print(prediction[0])\n",
    "  if(what_you_looking == prediction[0]) :\n",
    "      cv2.putText(image, prediction[0], (10, 30), cv2.FONT_HERSHEY_SIMPLEX,1.0, (0, 0, 255), 3)\n",
    "      cv2.imshow(\"Image\", image_show)\n",
    "      cv2.waitKey(0)\n",
    "      if cv2.waitKey(30) & 0xFF == 27:  # Tekan 'Esc' untuk keluar\n",
    "          break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982edac1-301c-4ebe-bdb1-d9c6a64568cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
